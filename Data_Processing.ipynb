{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jari78fYx4j"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import random, os, json, re, math, statistics\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "from numpy import save\n",
        "import scipy as sp\n",
        "from scipy import io\n",
        "import cv2 as cv \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, Dropout, Flatten, MaxPooling2D, Activation\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovCs3G6eY_O1"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R3-pbtiZCz7"
      },
      "source": [
        "# Download dataset\n",
        "gdd.download_file_from_google_drive(file_id='15M2oVwpl1UwUgreZDXj1QlLY8pv0cdSl',\n",
        "                                    dest_path='./RetailDataset.zip',\n",
        "                                    unzip=True)\n",
        "os.remove('./RetailDataset.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdUBC4NQZLIB"
      },
      "source": [
        "folder = './train2019/'\n",
        "lst = os.listdir(folder)\n",
        "lst.sort()\n",
        "\n",
        "# Encoding each class\n",
        "class_name = {'stationery':0, 'puffed_food':1, 'dried_fruit':2, 'dried_food':3, 'instant_drink':4, 'instant_noodles':5,\n",
        "              'dessert':6, 'drink':7, 'alcohol':8, 'milk':9, 'canned_food':10, 'chocolate':11,\n",
        "              'gum':12, 'candy':13, 'seasoner':14, 'personal_hygiene':15, 'tissue':16}\n",
        "\n",
        "# Import image information\n",
        "with open('./drive/My Drive/MSc Project/instances_train2019.json') as json_data:\n",
        "  instances = json.load(json_data)\n",
        "\n",
        "# Create dictionary that links product SKU to class\n",
        "class_code = {}\n",
        "for product in instances['__raw_Chinese_name_df']:\n",
        "  class_code[product['code']] = [product['sku_class'],class_name[product['sku_class']]]\n",
        "\n",
        "# Save class_code in .json file\n",
        "json_data = json.dumps(class_code)\n",
        "f = open('./drive/My Drive/MSc Project/class_code.json','w')\n",
        "f.write(json_data)\n",
        "f.close()\n",
        "# Load class_code\n",
        "with open('./drive/My Drive/MSc Project/class_code.json') as json_data:\n",
        "  class_code = json.load(json_data)\n",
        "\n",
        "def extract_code(name):\n",
        "  '''\n",
        "  Arg:\n",
        "    name: string, image name\n",
        "  Return:\n",
        "    sku code extracted from image name\n",
        "  '''\n",
        "  return str(int(re.split('-|_|~',name)[0]))\n",
        "\n",
        "class_lst = []\n",
        "for name in lst:\n",
        "  key = extract_code(name)\n",
        "  class_lst.append(class_code[key][1])\n",
        "\n",
        "# Separate image names into .txt files according to class\n",
        "if not os.path.exists('./classes'):\n",
        "    os.makedirs('./classes')\n",
        "for num in range(len(lst)):\n",
        "  file_name = './classes/class_'+str(class_lst[num])+'.txt'\n",
        "  open(file_name,'a').write(lst[num]+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khgqe1yBaVlQ"
      },
      "source": [
        "### Exploratory Data Analysis\n",
        "class_count = []\n",
        "for num in range(0,17):\n",
        "  file_name = './classes/class_'+str(num)+'.txt'\n",
        "  lines = open(file_name).readlines()\n",
        "  class_count.append(len(lines))\n",
        "\n",
        "### Visualisaiton of Data Distribution\n",
        "classes = ['stationery 0', 'puffed_food 1', 'dried_fruit 2', 'dried_food 3', 'instant_drink 4', 'instant_noodles 5',\n",
        "              'dessert 6', 'drink 7', 'alcohol 8', 'milk 9', 'canned_food 10', 'chocolate 11',\n",
        "              'gum 12', 'candy 13', 'seasoner 14', 'personal_hygiene 15', 'tissue 16']\n",
        "fig, ax = plt.subplots(figsize=(15,12))\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.set_xlim([0,7000])\n",
        "y_pos = [i for i, _ in enumerate(classes)]\n",
        "plt.barh(y_pos, class_count, alpha=0.7)\n",
        "ylocs, ylabs = plt.yticks()\n",
        "plt.ylabel('Class', fontsize=20)\n",
        "plt.xlabel('Number of Examples', fontsize=20)\n",
        "plt.title('Data Distribution',fontsize=24)\n",
        "plt.yticks(y_pos, classes, ha='right', fontsize=20)\n",
        "plt.xticks(fontsize=18)\n",
        "for i, v in enumerate(class_count):\n",
        "    ax.text(v + 3, i - 0.15, str(v), color='#1f77b4', alpha=0.9, fontweight='bold',fontsize=20)\n",
        "plt.savefig('Data Distribution.png', bbox_inches='tight')\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKG7xeJ4ajFe"
      },
      "source": [
        "### Data Splitting\n",
        "y_test = []\n",
        "y_val = []\n",
        "y_train = []\n",
        "train_class_count = []\n",
        "for num in range(0,17):\n",
        "  # Shuffle image names within each class\n",
        "  file_name = './classes/class_'+str(num)+'.txt'\n",
        "  lines = open(file_name).readlines()\n",
        "  random.shuffle(lines)\n",
        "\n",
        "  # Split each class file into train:validation:test with a proportion of 8:1:1\n",
        "  test_val_num = int(len(lines)/10)\n",
        "  train_num = len(lines) - test_val_num*2\n",
        "  train_class_count.append(train_num)\n",
        "  y_test += [num]*test_val_num\n",
        "  y_val += [num]*test_val_num\n",
        "  y_train += [num]*train_num\n",
        "  open('x_test_name.txt','a').writelines(lines[:test_val_num])\n",
        "  open('x_val_name.txt','a').writelines(lines[test_val_num:2*test_val_num])\n",
        "  # Overwrite class file, so that it only contains training data\n",
        "  open(file_name,'w').writelines(lines[2*test_val_num:])\n",
        "  #open('x_train_name.txt','a').writelines(lines[2*test_val_num:])\n",
        "\n",
        "# Save y_train, y_val and y_test\n",
        "#save('y_train.npy', np.array(y_train))\n",
        "save('y_test.npy', np.array(y_test))\n",
        "save('y_val.npy', np.array(y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anu8Z6J5a1fv"
      },
      "source": [
        "### Distribution of Raw Training Data\n",
        "classes = ['stationery 0', 'puffed_food 1', 'dried_fruit 2', 'dried_food 3', 'instant_drink 4', 'instant_noodles 5',\n",
        "              'dessert 6', 'drink 7', 'alcohol 8', 'milk 9', 'canned_food 10', 'chocolate 11',\n",
        "              'gum 12', 'candy 13', 'seasoner 14', 'personal_hygiene 15', 'tissue 16']\n",
        "fig, ax = plt.subplots(figsize=(15,12))\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.set_xlim([0,5800])\n",
        "y_pos = [i for i, _ in enumerate(classes)]\n",
        "plt.barh(y_pos, train_class_count, alpha=0.7)\n",
        "ylocs, ylabs = plt.yticks()\n",
        "plt.ylabel('Class', fontsize=20)\n",
        "plt.xlabel('Number of Examples', fontsize=20)\n",
        "plt.title('Distribution of Raw Training Data',fontsize=24)\n",
        "plt.yticks(y_pos, classes, ha='right', fontsize=20)\n",
        "plt.xticks(fontsize=18)\n",
        "for i, v in enumerate(train_class_count):\n",
        "    ax.text(v + 3, i - 0.15, str(v), color='#1f77b4', alpha=0.9, fontweight='bold',fontsize=20)\n",
        "plt.savefig('Distribution of Raw Training Data.png', bbox_inches='tight')\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlHdQ8aIa-1c"
      },
      "source": [
        "### Resampling Training Data\n",
        "print('median:',statistics.median(train_class_count))\n",
        "print('mean:',np.mean(train_class_count))\n",
        "\n",
        "# set number of examples in each class to be 2400,\n",
        "# so downsample 7 classes and upsample 10 classes\n",
        "y_train = []\n",
        "train_class_count_new = []\n",
        "thres = 2400\n",
        "for num in range(0,17):\n",
        "  # Shuffle image names within each class\n",
        "  file_name = './classes/class_'+str(num)+'.txt'\n",
        "  lines = open(file_name).readlines()\n",
        "  random.shuffle(lines)\n",
        "\n",
        "  if len(lines)<thres:\n",
        "    # upsampling\n",
        "    repeat_lines = random.sample(lines, thres - len(lines)) # random repeating\n",
        "    open('x_train_name.txt','a').writelines(lines+repeat_lines)\n",
        "    length = len(lines+repeat_lines)\n",
        "    train_class_count_new.append(length)\n",
        "  else:\n",
        "    # downsampling\n",
        "    sample_lines = random.sample(lines, thres) # random sampling\n",
        "    open('x_train_name.txt','a').writelines(sample_lines)\n",
        "    length = len(sample_lines)\n",
        "    train_class_count_new.append(length)\n",
        "\n",
        "  y_train += [num]*length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iY2ZPyebF8c"
      },
      "source": [
        "# Shuffle the whole training data\n",
        "lines = open('x_train_name.txt').readlines()\n",
        "list_combined = list(zip(lines,y_train))\n",
        "random.shuffle(list_combined)\n",
        "lines, y_train = zip(*list_combined)\n",
        "# overwrite x_train_name.txt\n",
        "open('x_train_name.txt','w').writelines(lines)\n",
        "save('y_train.npy', np.array(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHbo5BDEbYyU"
      },
      "source": [
        "### Distribution of Resampled Training Data\n",
        "classes = ['stationery 0', 'puffed_food 1', 'dried_fruit 2', 'dried_food 3', 'instant_drink 4', 'instant_noodles 5',\n",
        "              'dessert 6', 'drink 7', 'alcohol 8', 'milk 9', 'canned_food 10', 'chocolate 11',\n",
        "              'gum 12', 'candy 13', 'seasoner 14', 'personal_hygiene 15', 'tissue 16']\n",
        "fig, ax = plt.subplots(figsize=(15,12))\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.set_xlim([0,5800])\n",
        "y_pos = [i for i, _ in enumerate(classes)]\n",
        "plt.barh(y_pos, train_class_count_new, alpha=0.7)\n",
        "ylocs, ylabs = plt.yticks()\n",
        "plt.ylabel('Class', fontsize=20)\n",
        "plt.xlabel('Number of Examples', fontsize=20)\n",
        "plt.title('Distribution of Resampled Training Data',fontsize=24)\n",
        "plt.yticks(y_pos, classes, ha='right', fontsize=20)\n",
        "plt.xticks(fontsize=18)\n",
        "for i, v in enumerate(train_class_count_new):\n",
        "    ax.text(v + 3, i - 0.15, str(v), color='#1f77b4', alpha=0.9, fontweight='bold',fontsize=20)\n",
        "plt.savefig('Distribution of Resampled Training Data.png', bbox_inches='tight')\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKrdZilGb9No"
      },
      "source": [
        "def generate_data(path,num,img_name):\n",
        "  data = np.zeros((num,256,256,3))\n",
        "  for i in range(num):\n",
        "    crop_img = cv.imread(path+img_name[i].strip())[172:1772,496:2096]/255 # crop image to (1600,1600)\n",
        "    data[i] = cv.resize(crop_img, (256,256)) # resize image to (256,256)\n",
        "  return data\n",
        "\n",
        "### generate validation data\n",
        "x_val = generate_data('./train2019/',len(y_val),x_val_name)\n",
        "save('./drive/My Drive/MSc Project/x_val.npy', x_val)\n",
        "\n",
        "### generate test data\n",
        "x_test = generate_data('./train2019/',len(y_test),x_test_name)\n",
        "save('./drive/My Drive/MSc Project/x_test.npy', x_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}